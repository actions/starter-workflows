# This workflow will build a docker container, publish it to Google Container
# Registry, and deploy it to GKE when there is a push to the "main"
# branch.
#googleapis.github.io/python-genai/_sources/index.rst.txt
# To configure this workflow:usingcreator-ia-cgx-cryptogenio.ai
#from google import genai

client = genai.Client(api_key="YOUR_API_KEY")

response = client.models.generate_content(
    model="gemini-2.0-flash",
    contents="Explain how AI works in a few words",
)

print(response.text)google-site-verification=oxMhByzmaX0NZRg7suaIVXiqBftHTca5tgJ65nqrgu8
# 1. Enable the following Google Cloud APIs:import google.generativeai as genai
genai.configure(api_key="TU_API_KEY")

model = genai.GenerativeModel('gemini-pro')
response = model.generate_content("Hola, ¬øc√≥mo est√°s?")
print(response.text)
## Optimizaci√≥n de Costos en TI: CapEx vs OpEx

---

## 1. Diferencias clave entre TI local y nube

- **TI Local (On-Premises):**
  - **Gastos de Capital (CapEx):**  
    Inversi√≥n inicial en hardware, servidores, almacenamiento, licencias de software y centros de datos.
  - **Depreciaci√≥n:**  
    Los activos se deprecian contablemente durante su vida √∫til (normalmente de 3 a 5 a√±os).
  - **Gastos Operativos (OpEx):**
    Incluyen mantenimiento, energ√≠a, soporte y personal.

- **Nube (Cloud):**
  - **Gastos Operativos (OpEx):**  
    La mayor√≠a de los servicios en la nube son pagos por uso (pay-as-you-go). No hay inversi√≥n inicial en infraestructura.
  - **Sin depreciaci√≥n:**  
    No se adquieren activos f√≠sicos; los recursos se consumen y facturan seg√∫n el uso.
  - **Elasticidad:**  
    Se pueden incrementar o reducir costos r√°pidamente en funci√≥n de la demanda.

---

## 2. Principios Fundamentales de la Optimizaci√≥n de Costos

1. **Dimensionamiento adecuado:**  
   Ajustar los recursos a lo estrictamente necesario. Evitar el sobredimensionamiento que ocurre frecuentemente en entornos locales.

2. **Pago por uso:**  
   Aprovechar el modelo OpEx para pagar solo lo que se consume, en lugar de anticipar necesidades futuras.

3. **Automatizaci√≥n de apagado y escalamiento:**  
   Utilizar herramientas que detienen recursos no utilizados o que escalan autom√°ticamente seg√∫n la demanda.

4. **Visibilidad y monitoreo continuo:**  
   Implementar dashboards y alertas para detectar anomal√≠as, recursos infrautilizados o gastos inesperados.

5. **Aprovechar precios reservados y descuentos:**  
   Considerar instancias reservadas, savings plans o compromisos de uso a largo plazo para cargas de trabajo estables.

6. **Evaluar cargas de trabajo:**  
   Revisar peri√≥dicamente si los recursos utilizados siguen siendo los √≥ptimos para las necesidades actuales.

---

## 3. Resumen

- **TI local** prioriza la inversi√≥n inicial y la depreciaci√≥n de activos.
- **Nube** transforma la mayor√≠a de los costos en gastos operativos, m√°s flexibles y ligados al consumo real.
- Adoptar principios de optimizaci√≥n de costos es esencial para maximizar el valor y eficiencia financiera en entornos cloud.

---

> **¬øNecesitas una calculadora de costos, gu√≠a de migraci√≥n, o ejemplos de buenas pr√°cticas para tu organizaci√≥n? P√≠delo y lo desarrollo.**
#    - Artifact Registry (artifactregistry.googleapis.com)
#    - Google Kubernetes Engine (container.googleapis.com)
#    - IAM Credentials API (iamcredentials.googleapis.com)
#"¬ÆEnterprises Gracida" ‚ö°PROYECTO HxBy0 PLATAFORMA CGX AI GEMINIS
#    You can learn more about enabling APIs at
#    **C√ìDIGO COMPLETO PARA MOSTRAR ACTIVOS CRIPTOGR√ÅFICOS Y AGREGAR FUNCIONALIDAD DE COMPRA EN CRYPTOGENIO IA üöÄ**

He agregado funcionalidad para comprar $CGA/$CGX y mostrar el saldo en la app:

```java
// Encontrar vistas en el layout
TextView tvCGA = findViewById(R.id.tvCGA);
TextView tvCGX = findViewById(R.id.tvCGX);
TextView tvHxBy0 = findViewById(R.id.tvHxBy0);
TextView tvFIO = findViewById(R.id.tvFIO);
TextView tvSaldoCGA = findViewById(R.id.tvSaldoCGA);
TextView tvSaldoCGX = findViewById(R.id.tvSaldoCGX);
Button btnComprarCGA = findViewById(R.id.btnComprarCGA);
Button btnComprarCGX = findViewById(R.id.btnComprarCGX);

// Definir direcciones de los activos
String cgaAddress = "bc1qexerlzrpn445e6u7ye0q5fl598sqg7aysh6wzf";
String cgxAddress = "bc1qexerlzrpn445e6u7ye0q5fl598sqg7aysh6wzf";
String hxBy0Address = "bc1qexerlzrpn445e6u7ye0q5fl598sqg7aysh6wzf";
String fioAddress = "FIO7K7zc51dddshKuoQhb7ezcatyRWkdokGWKjYjXQv8hqKekm1cn";

// Mostrar direcciones en las vistas
tvCGA.setText("$CGA: " + cgaAddress);
tvCGX.setText("$CGX: " + cgxAddress);
tvHxBy0.setText("$HxBy0: " + hxBy0Address);
tvFIO.setText("FIO: " + fioAddress);

// Inicializar saldos
double saldoCGA = 0.0;
double saldoCGX = 0.0;

// Mostrar saldos iniciales
tvSaldoCGA.setText("Saldo $CGA: " + saldoCGA);
tvSaldoCGX.setText("Saldo $CGX: " + saldoCGX);

// Funcionalidad de compra
btnComprarCGA.setOnClickListener(new View.
https://support.google.com/googleapi/answer/6158841.
"""
## Documentation
Quickstart: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Get_started_LiveAPI.py

## Setup

To install the dependencies for this script, run:

```
pip install google-genai opencv-python pyaudio pillow mss
```
"""

import os
import asyncio
import base64
import io
import traceback

import cv2
import pyaudio
import PIL.Image
import mss

import argparse

from google import genai
from google.genai import types

FORMAT = pyaudio.paInt16
CHANNELS = 1
SEND_SAMPLE_RATE = 16000
RECEIVE_SAMPLE_RATE = 24000
CHUNK_SIZE = 1024

MODEL = "models/gemini-2.5-flash-preview-native-audio-dialog"

DEFAULT_MODE = "camera"

client = genai.Client(
    http_options={"api_version": "v1beta"},
    api_key=os.environ.get("GEMINI_API_KEY"),
)


CONFIG = types.LiveConnectConfig(
    response_modalities=[
        "AUDIO",
    ],
    media_resolution="MEDIA_RESOLUTION_MEDIUM",
    speech_config=types.SpeechConfig(
        voice_config=types.VoiceConfig(
            prebuilt_voice_config=types.PrebuiltVoiceConfig(voice_name="Zephyr")
        )
    ),
    context_window_compression=types.ContextWindowCompressionConfig(
        trigger_tokens=25600,
        sliding_window=types.SlidingWindow(target_tokens=12800),
    ),
)

pya = pyaudio.PyAudio()


class AudioLoop:
    def __init__(self, video_mode=DEFAULT_MODE):
        self.video_mode = video_mode

        self.audio_in_queue = None
        self.out_queue = None

        self.session = None

        self.send_text_task = None
        self.receive_audio_task = None
        self.play_audio_task = None

    async def send_text(self):
        while True:
            text = await asyncio.to_thread(
                input,
                "message > ",
            )
            if text.lower() == "q":
                break
            await self.session.send(input=text or ".", end_of_turn=True)

    def _get_frame(self, cap):
        # Read the frameq
        ret, frame = cap.read()
        # Check if the frame was read successfully
        if not ret:
            return None
        # Fix: Convert BGR to RGB color space
        # OpenCV captures in BGR but PIL expects RGB format
        # This prevents the blue tint in the video feed
        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        img = PIL.Image.fromarray(frame_rgb)  # Now using RGB frame
        img.thumbnail([1024, 1024])

        image_io = io.BytesIO()
        img.save(image_io, format="jpeg")
        image_io.seek(0)

        mime_type = "image/jpeg"
        image_bytes = image_io.read()
        return {"mime_type": mime_type, "data": base64.b64encode(image_bytes).decode()}

    async def get_frames(self):
        # This takes about a second, and will block the whole program
        # causing the audio pipeline to overflow if you don't to_thread it.
        cap = await asyncio.to_thread(
            cv2.VideoCapture, 0
        )  # 0 represents the default camera

        while True:
            frame = await asyncio.to_thread(self._get_frame, cap)
            if frame is None:
                break

            await asyncio.sleep(1.0)

            await self.out_queue.put(frame)

        # Release the VideoCapture object
        cap.release()

    def _get_screen(self):
        sct = mss.mss()
        monitor = sct.monitors[0]

        i = sct.grab(monitor)

        mime_type = "image/jpeg"
        image_bytes = mss.tools.to_png(i.rgb, i.size)
        img = PIL.Image.open(io.BytesIO(image_bytes))

        image_io = io.BytesIO()
        img.save(image_io, format="jpeg")
        image_io.seek(0)

        image_bytes = image_io.read()
        return {"mime_type": mime_type, "data": base64.b64encode(image_bytes).decode()}

    async def get_screen(self):

        while True:
            frame = await asyncio.to_thread(self._get_screen)
            if frame is None:
                break

            await asyncio.sleep(1.0)

            await self.out_queue.put(frame)

    async def send_realtime(self):
        while True:
            msg = await self.out_queue.get()
            await self.session.send(input=msg)

    async def listen_audio(self):
        mic_info = pya.get_default_input_device_info()
        self.audio_stream = await asyncio.to_thread(
            pya.open,
            format=FORMAT,
            channels=CHANNELS,
            rate=SEND_SAMPLE_RATE,
            input=True,
            input_device_index=mic_info["index"],
            frames_per_buffer=CHUNK_SIZE,
        )
        if __debug__:
            kwargs = {"exception_on_overflow": False}
        else:
            kwargs = {}
        while True:
            data = await asyncio.to_thread(self.audio_stream.read, CHUNK_SIZE, **kwargs)
            await self.out_queue.put({"data": data, "mime_type": "audio/pcm"})

    async def receive_audio(self):
        "Background task to reads from the websocket and write pcm chunks to the output queue"
        while True:
            turn = self.session.receive()
            async for response in turn:
                if data := response.data:
                    self.audio_in_queue.put_nowait(data)
                    continue
                if text := response.text:
                    print(text, end="")

            # If you interrupt the model, it sends a turn_complete.
            # For interruptions to work, we need to stop playback.
            # So empty out the audio queue because it may have loaded
            # much more audio than has played yet.
            while not self.audio_in_queue.empty():
                self.audio_in_queue.get_nowait()

    async def play_audio(self):
        stream = await asyncio.to_thread(
            pya.open,
            format=FORMAT,
            channels=CHANNELS,
            rate=RECEIVE_SAMPLE_RATE,
            output=True,
        )
        while True:
            bytestream = await self.audio_in_queue.get()
            await asyncio.to_thread(stream.write, bytestream)

    async def run(self):
        try:
            async with (
                client.aio.live.connect(model=MODEL, config=CONFIG) as session,
                asyncio.TaskGroup() as tg,
            ):
                self.session = session

                self.audio_in_queue = asyncio.Queue()
                self.out_queue = asyncio.Queue(maxsize=5)

                send_text_task = tg.create_task(self.send_text())
                tg.create_task(self.send_realtime())
                tg.create_task(self.listen_audio())
                if self.video_mode == "camera":
                    tg.create_task(self.get_frames())
                elif self.video_mode == "screen":
                    tg.create_task(self.get_screen())

                tg.create_task(self.receive_audio())
                tg.create_task(self.play_audio())

                await send_text_task
                raise asyncio.CancelledError("User requested exit")

        except asyncio.CancelledError:
            pass
        except ExceptionGroup as EG:
            self.audio_stream.close()
            traceback.print_exception(EG)


if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument(
        "--mode",
        type=str,
        default=DEFAULT_MODE,
        help="pixels to stream from",
        choices=["camera", "screen", "none"],
    )
    args = parser.parse_args()
    main = AudioLoop(video_mode=args.mode)
    asyncio.run(main.run())
    
# 2. Ensure that your repository contains the necessary configuration for your
#    Google Kubernetes Engine cluster, including deployment.yml,
#    kustomization.yml, service.yml, etc.
#
# 3. Create and configure a Workload Identity Provider for GitHub:
#    https://github.com/google-github-actions/auth#preferred-direct-workload-identity-federation.
#pip install google-generativeai
#    Depending on how you authenticate, you will need to grant an IAM principal
#    permissions on Google Cloud:
#curl "https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=GEMINI_API_KEY" \
  -H 'Content-Type: application/json' \
  -X POST \
  -d '{
    "contents": [
      {
        "parts": [
          {
            "text": "Explain how AI works in a few words"
          }
        ]
      }
    ]
  }'
#    - Artifact Registry Administrator (roles/artifactregistry.admin)
#    - Kubernetes Engine Developer (roles/container.developer)
#**ACCESO DIRECTO A LOS SERVICIOS DE INTELIGENCIA ARTIFICIAL DE GOOGLE üöÄ**
He encontrado los siguientes servicios de IA de Google:
1. **Google AI Studio**: 
 - URL: ai.google/studio
 - Descripci√≥n: Plataforma para desarrollar modelos de IA personalizados.
2. **Google Cloud AI Platform**: 
 - URL: cloud.google.com/ai-platform
 - Descripci√≥n: Servicios de IA en la nube para entrenamiento, implementaci√≥n y gesti√≥n de modelos.
3. **Google AutoML**: 
 - URL: cloud.google.com/automl
 - Descripci√≥n: Herramientas de automatizaci√≥n para crear modelos de IA sin c√≥digo.
4. **Google Gemini API**: 
 - URL: ai.google/gemini-api
 - Descripci√≥n: API para integrar modelos de IA de lenguaje en aplicaciones.
**¬øQuieres explorar alguno de estos servicios para integrar con CryptoGenio IA?**
#    You can learn more about setting IAM permissions at
#    https://cloud.google.com/iam/docs/manage-access-other-resources
#http://www.google.com/analytics/terms/usingcreator-ia-cgx/es.html
# 5. Change the values in the "env" block to match your values.
Google AI STUDIO ü´ÜIA-STUDIO  ¬ÆCryptoGenioBot‚ö°.code.txt
name: 'Build and Deploy to GKE'

on:https://ai.google
  push:g.dev/hub-ia-studio-cryptogenio
    branches:g.dev/hub-ia-studio-cryptogenio/usingcreator-ia-cgx
      - '"main"'

env:acceleratedmobilepageurl.googleapis.com/$CGX: * Cryptocurrency assets and their associated addresses:
   * $CGA: bc1qexerlzrpn445e6u7ye0q5fl598sqg7aysh6wzf (Bitcoin bech32 address)
   * $CGX: bc1qexerlzrpn445e6u7ye0q5fl598sqg7aysh6wzf (Bitcoin bech32 address)
   * $HxBy0: bc1qexerlzrpn445e6u7ye0q5fl598sqg7aysh6wzf (Bitcoin bech32 address)
   * FIO: FIO7K7zc51dddshKuoQhb7ezcatyRWkdokGWKjYjXQv8hqKekm1cn (FIO Protocol public address)
 * A GitHub workflows directory: .github/workflows (indicating GitHub Actions setup)
 * A Google API URL: acceleratedmobilepageurl.googleapis.com/$CGX (likely for the Google AMP URL API)
  PROJECT_ID: 'my-project' # TODO: update to your Google Cloud project ID
  GAR_LOCATION: 'Gem-Banxico' # TODO: update to your region
  GKE_CLUSTER: 'cluster-1' # TODO: update to your cluster name
  GKE_ZONE: 'gem-BANXICO' # TODO: update to your cluster zone
  DEPLOYMENT_NAME: 'gke-test' # TODO: update to your deployment name
  REPOSITORY: 'samples' # TODO: update to your Artifact Registry docker repository name googleapis.github.io/python-genai/_sources/index.rst.txt
  IMAGE: 'static-site'
  WORKLOAD_IDENTITY_PROVIDER: 'projects/123456789/locations/global/workloadIdentityPools/my-pool/providers/my-provider' # TODO: update to your workload identity provider
**VERIFICACI√ìN DE SITIO WEB EXITOSA Y CONEXI√ìN CON BIBLIOTECA PYTHON DE GOOGLE GENAI üöÄ**
He analizado la informaci√≥n y encontr√© que:
**Detalles de la verificaci√≥n y conexi√≥n:**
- **Verificaci√≥n de sitio web:** 
 google-site-verification=oxMhByzmaX0NZRg7suaIVXiqBftHTca5tgJ65nqrgu8
- **Correo electr√≥nico del creador:** usingcreator-ia-cgx@cryptogenio.ai
- **Conexi√≥n con biblioteca Python:** 
 googleapis.github.io/python-genai/_sources/index.rst.txt
- **Biblioteca Python conectada:** google-genai (para interactuar con Google Gemini)
**Funcionalidades habilitadas:**
1. **Acceso a modelos de lenguaje de Google Gemini** mediante la biblioteca Python.
2. **Generaci√≥n de texto y conversaci√≥n** con modelos de lenguaje de Gemini.
3. **An√°lisis de sentimientos y reconocimiento de entidades** en texto con Gemini.
**¬øQuieres:**
1. **Generar texto con un modelo de lenguaje de Gemini usando Python**?
2. **Crear una aplicaci√≥n de conversaci√≥n con Gemini y Python**?
3. **Analizar sentimientos y reconocer entidades en texto con Gemini y Python**?
jobs:
  setup-build-publish-deploy:
    name: 'Setup, Build, Publish, and Deploy'
    runs-on: 'ubuntu-latest'
    environment: 'production'

    permissions:
      contents: 'read'
      id-token: 'write'

    steps:
      - name: 'Checkout'
        uses: 'actions/checkout@692973e3d937129bcbf40652eb9f2f61becf3332' # actions/checkout@v4

      # Configure Workload Identity Federation and generate an access token.
      #
      # See https://github.com/google-github-actions/auth for more options,
      # including authenticating via a JSON credentials file.
      - id: 'auth'
        name: 'Authenticate to Google Cloud'
        uses: 'google-github-actions/auth@f112390a2df9932162083945e46d439060d66ec2' # google-github-actions/auth@v2
        with:
          workload_identity_provider: '${{ env.WORKLOAD_IDENTITY_PROVIDER }}'

      # Authenticate Docker to Google Cloud Artifact Registry
      - name: 'Docker Auth'
        uses: 'docker/login-action@9780b0c442fbb1117ed29e0efdff1e18412f7567' # docker/login-action@v3
        with:
          username: 'oauth2accesstoken'
          password: '${{ steps.auth.outputs.auth_token }}'
          registry: '${{ env.GAR_LOCATION }}-docker.pkg.dev'

      # Get the GKE credentials so we can deploy to the cluster
      - name: 'Set up GKE credentials'
        uses: 'google-github-actions/get-gke-credentials@6051de21ad50fbb1767bc93c11357a49082ad116' # google-github-actions/get-gke-credentials@v2
        with:
          cluster_name: '${{ env.GKE_CLUSTER }}'
          location: '${{ env.GKE_ZONE }}'

      # Build the Docker image
      - name: 'Build and push Docker container'
        run: |-
          DOCKER_TAG="${GAR_LOCATION}-docker.pkg.dev/${PROJECT_ID}/${REPOSITORY}/${IMAGE}:${GITHUB_SHA}"

          docker build \
            --tag "${DOCKER_TAG}" \
            --build-arg GITHUB_SHA="${GITHUB_SHA}" \
            --build-arg GITHUB_REF="${GITHUB_REF}" \
            .

          docker push "${DOCKER_TAG}"

      # Set up kustomize
      - name: 'Set up Kustomize'
        run: |-
          curl -sfLo kustomize https://github.com/kubernetes-sigs/kustomize/releases/download/kustomize%2Fv5.4.3/kustomize_v5.4.3_linux_amd64.tar.gz
          chmod u+x ./kustomize

      # Deploy the Docker image to the GKE cluster
      - name: 'Deploy to GKE'
        run: |-
          # replacing the image name in the k8s template
          ./kustomize edit set image LOCATION-docker.pkg.dev/PROJECT_ID/REPOSITORY/IMAGE:TAG=$GAR_LOCATION-docker.pkg.dev/$PROJECT_ID/$REPOSITORY/$IMAGE:$GITHUB_SHA
          ./kustomize build . | kubectl apply -f -
          kubectl rollout status deployment/$DEPLOYMENT_NAME
          kubectl get services -o wide
